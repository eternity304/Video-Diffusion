{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a334621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/horai.dgpsrv/ondemand28/harryscz/diffusion'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '8'\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import math\n",
    "import yaml\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import imageio\n",
    "import torch\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612bf3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(arg_list=None):\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Unconditioned Video Diffusion Inference\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dataset-path\", type=str, required=True,\n",
    "        help=\"Directory containing input reference videos.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--pretrained-model-name-or-path\", type=str, required=True,\n",
    "        help=\"Path or HF ID where transformer/vae/scheduler are stored.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--checkpoint-path\", type=str, required=True,\n",
    "        help=\"Path to fine‚Äêtuned checkpoint containing transformer state_dict.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output-dir\", type=str, required=True,\n",
    "        help=\"Where to write generated videos.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model-config\", type=str, required=True,\n",
    "        help=\"YAML file describing model params (height, width, num_reference, num_target, etc.)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch-size\", type=int, default=1,\n",
    "        help=\"Batch size per device (usually 1 for inference).\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-inference-steps\", type=int, default=50,\n",
    "        help=\"Number of reverse diffusion steps to run.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--mixed-precision\", type=str, default=\"bf16\",\n",
    "        help=\"Whether to run backbone in 'fp16', 'bf16', or 'fp32'.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--seed\", type=int, default=42,\n",
    "        help=\"Random seed for reproducibility.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--shuffle\", type=int, default=False,\n",
    "        help=\"Whether to shuffle dataset. Usually False for inference.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--is-uncond\", type=bool, default=False,\n",
    "        help=\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sample-frames\", type=int, default=50\n",
    "    )\n",
    "\n",
    "    # If arg_list is None, argparse picks up sys.argv; \n",
    "    # otherwise it treats arg_list as the full argv list.\n",
    "    return parser.parse_args(arg_list)\n",
    "\n",
    "args = [\n",
    "    \"--dataset-path\", \"/scratch/ondemand28/harryscz/head_audio/head/data/vfhq-fit\",\n",
    "    \"--pretrained-model-name-or-path\", \"/scratch/ondemand28/harryscz/model/CogVideoX-2b\",\n",
    "    \"--checkpoint-path\",  \"/scratch/ondemand28/harryscz/head_audio/trainOutput/checkpoint-6000.pt\",\n",
    "    \"--output-dir\",  \"/scratch/ondemand28/harryscz/diffusion/videoOut\",\n",
    "    \"--model-config\",  \"/scratch/ondemand28/harryscz/diffusion/train/model_config.yaml\",\n",
    "    \"--batch-size\",  \"1\",\n",
    "    \"--num-inference-steps\",  \"50\",\n",
    "    \"--mixed-precision\",  \"no\",\n",
    "    \"--seed\",  \"42\",\n",
    "    \"--shuffle\",  \"0\",\n",
    "    \"--sample-frames\", \"29\"\n",
    "]\n",
    "\n",
    "args = parse_args(args)\n",
    "\n",
    "with open(args.model_config, \"r\") as f: model_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32793233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2146331/1469107812.py\", line 32, in <module>\n",
      "    logger.info(\"Accelerator state:\", accelerator.state)\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/logging/__init__.py\", line 1806, in info\n",
      "    self.log(INFO, msg, *args, **kwargs)\n",
      "  File \"/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/accelerate/logging.py\", line 63, in log\n",
      "    self.logger.log(level, msg, *args, **kwargs)\n",
      "Message: 'Accelerator state:'\n",
      "Arguments: (Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      ",)\n",
      "07/23/2025 12:07:20 - INFO - __main__ - Number of test examples: 6814\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.utils import DistributedDataParallelKwargs, ProjectConfiguration, set_seed\n",
    "from accelerate.logging import get_logger\n",
    "\n",
    "with open(args.model_config, \"r\") as f: model_config = yaml.safe_load(f)\n",
    "if args.mixed_precision.lower() == \"fp16\":\n",
    "    dtype = torch.float16\n",
    "elif args.mixed_precision.lower() == \"bf16\":\n",
    "    dtype = torch.bfloat16\n",
    "else:\n",
    "    dtype = torch.float32\n",
    "\n",
    "accelerator_project_config = ProjectConfiguration(project_dir=args.output_dir,\n",
    "                                                    logging_dir=os.path.join(args.output_dir, \"logs\"))\n",
    "ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=False)\n",
    "accelerator = Accelerator(mixed_precision=args.mixed_precision,\n",
    "                            project_config=accelerator_project_config,\n",
    "                            kwargs_handlers=[ddp_kwargs])\n",
    "\n",
    "# 2.4 Set random seed\n",
    "if args.seed is not None:\n",
    "    set_seed(args.seed + accelerator.process_index)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger.info(\"Accelerator state:\", accelerator.state)\n",
    "\n",
    "from data.VideoDataset import *\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "dataset = VideoPathDataset(\n",
    "    source_dir=args.dataset_path,\n",
    ")\n",
    "if args.shuffle:\n",
    "    sampler = DistributedSampler(\n",
    "        dataset,\n",
    "        num_replicas=accelerator.num_processes,\n",
    "        rank=accelerator.process_index,\n",
    "        shuffle=True\n",
    "    )\n",
    "else:\n",
    "    sampler = None\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    # sampler=sampler,\n",
    "    collate_fn=lambda x: x,   \n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    ")\n",
    "logger.info(f\"Number of test examples: {len(data_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b82f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_video(vae, video, grad=False):\n",
    "    video = video.to(accelerator.device, dtype=vae.dtype)\n",
    "    video = video.permute(0, 2, 1, 3, 4)  # [B, C, F, H, W]\n",
    "\n",
    "    if grad:\n",
    "        latent_dist = vae.encode(video).latent_dist.sample() * vae.config.scaling_factor\n",
    "    else: \n",
    "        with torch.no_grad(): latent_dist = vae.encode(video).latent_dist.sample() * vae.config.scaling_factor\n",
    "    return latent_dist.permute(0, 2, 1, 3, 4).to(memory_format=torch.contiguous_format)\n",
    "\n",
    "def decode_latents(vae, latents: torch.Tensor, grad=False) -> torch.Tensor:\n",
    "    latents = latents.permute(0, 2, 1, 3, 4)  # [batch_size, num_channels, num_frames, height, width]\n",
    "    latents = 1 / vae.config.scaling_factor * latents\n",
    "\n",
    "    if grad:\n",
    "        rames = vae.decode(latents).sample\n",
    "    else:\n",
    "        with torch.no_grad(): frames = vae.decode(latents).sample\n",
    "    return frames.permute(0,2,1,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48152545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoencoderKLCogVideoX(\n",
       "  (encoder): CogVideoXEncoder3D(\n",
       "    (conv_in): CogVideoXCausalConv3d(\n",
       "      (conv): CogVideoXSafeConv3d(3, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    )\n",
       "    (down_blocks): ModuleList(\n",
       "      (0): CogVideoXDownBlock3D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-2): 3 x CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): CogVideoXDownsample3D(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): CogVideoXDownBlock3D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (conv_shortcut): CogVideoXSafeConv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "          (1-2): 2 x CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): CogVideoXDownsample3D(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CogVideoXDownBlock3D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-2): 3 x CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): CogVideoXDownsample3D(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): CogVideoXDownBlock3D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (conv_shortcut): CogVideoXSafeConv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "          (1-2): 2 x CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid_block): CogVideoXMidBlock3D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x CogVideoXResnetBlock3D(\n",
       "          (nonlinearity): SiLU()\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): CogVideoXCausalConv3d(\n",
       "            (conv): CogVideoXSafeConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): CogVideoXCausalConv3d(\n",
       "            (conv): CogVideoXSafeConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "    (conv_act): SiLU()\n",
       "    (conv_out): CogVideoXCausalConv3d(\n",
       "      (conv): CogVideoXSafeConv3d(512, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (decoder): CogVideoXDecoder3D(\n",
       "    (conv_in): CogVideoXCausalConv3d(\n",
       "      (conv): CogVideoXSafeConv3d(16, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    )\n",
       "    (mid_block): CogVideoXMidBlock3D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x CogVideoXResnetBlock3D(\n",
       "          (nonlinearity): SiLU()\n",
       "          (norm1): CogVideoXSpatialNorm3D(\n",
       "            (norm_layer): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv_y): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(16, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (conv_b): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(16, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (norm2): CogVideoXSpatialNorm3D(\n",
       "            (norm_layer): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv_y): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(16, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (conv_b): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(16, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (conv1): CogVideoXCausalConv3d(\n",
       "            (conv): CogVideoXSafeConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): CogVideoXCausalConv3d(\n",
       "            (conv): CogVideoXSafeConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up_blocks): ModuleList(\n",
       "      (0): CogVideoXUpBlock3D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-3): 4 x CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (norm2): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): CogVideoXUpsample3D(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): CogVideoXUpBlock3D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (norm2): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (conv_shortcut): CogVideoXSafeConv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "          (1-3): 3 x CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (norm2): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): CogVideoXUpsample3D(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CogVideoXUpBlock3D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-3): 4 x CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (norm2): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): CogVideoXUpsample3D(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): CogVideoXUpBlock3D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (norm2): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (conv_shortcut): CogVideoXSafeConv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "          (1-3): 3 x CogVideoXResnetBlock3D(\n",
       "            (nonlinearity): SiLU()\n",
       "            (norm1): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (norm2): CogVideoXSpatialNorm3D(\n",
       "              (norm_layer): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv_y): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "              (conv_b): CogVideoXCausalConv3d(\n",
       "                (conv): CogVideoXSafeConv3d(16, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (conv1): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): CogVideoXCausalConv3d(\n",
       "              (conv): CogVideoXSafeConv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_out): CogVideoXSpatialNorm3D(\n",
       "      (norm_layer): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "      (conv_y): CogVideoXCausalConv3d(\n",
       "        (conv): CogVideoXSafeConv3d(16, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (conv_b): CogVideoXCausalConv3d(\n",
       "        (conv): CogVideoXSafeConv3d(16, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (conv_act): SiLU()\n",
       "    (conv_out): CogVideoXCausalConv3d(\n",
       "      (conv): CogVideoXSafeConv3d(128, 3, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "dtype = torch.float32\n",
    "\n",
    "from diffusers import AutoencoderKLCogVideoX\n",
    "\n",
    "vae = AutoencoderKLCogVideoX.from_pretrained(\n",
    "    args.pretrained_model_name_or_path, subfolder=\"vae\"\n",
    ")\n",
    "vae.eval().to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa3f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae, data_loader = accelerator.prepare(vae, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d07b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/horai.dgpsrv/ondemand28/harryscz/pytorch3d/pytorch3d/io/obj_io.py:551: UserWarning: Mtl file does not exist: /scratch/ondemand28/harryscz/head_audio/head/template.mtl\n",
      "  warnings.warn(f\"Mtl file does not exist: {f}\")\n"
     ]
    }
   ],
   "source": [
    "from model.flameObj import *\n",
    "\n",
    "flamePath = \"/scratch/ondemand28/harryscz/head_audio/head/code/flame/flame2023_no_jaw.npz\"\n",
    "sourcePath = \"/scratch/ondemand28/harryscz/head_audio/head/data/vfhq-fit\"\n",
    "dataPath = [os.path.join(os.path.join(sourcePath, data), \"fit.npz\") for data in os.listdir(sourcePath)]\n",
    "seqPath = \"/scratch/ondemand28/harryscz/head/_-91nXXjrVo_00/fit.npz\"\n",
    "\n",
    "head = Flame(flamePath, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6317aaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/ondemand28/harryscz/head_audio/head/data/vfhq-fit/g1eIAelVFq4_02/fit.npz',\n",
       " '/scratch/ondemand28/harryscz/head_audio/head/data/vfhq-fit/jJ62WENxR78_01/fit.npz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54079a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_video(vae, video, grad=False):\n",
    "    video = video.to(accelerator.device, dtype=vae.dtype)\n",
    "    video = video.permute(0, 2, 1, 3, 4)  # [B, C, F, H, W]\n",
    "\n",
    "    if grad:\n",
    "        latent_dist = vae.encode(video).latent_dist.sample() * vae.config.scaling_factor\n",
    "    else: \n",
    "        with torch.no_grad(): latent_dist = vae.encode(video).latent_dist.sample() * vae.config.scaling_factor\n",
    "    return latent_dist.permute(0, 2, 1, 3, 4).to(memory_format=torch.contiguous_format)\n",
    "\n",
    "def decode_latents(vae, latents: torch.Tensor, grad=False) -> torch.Tensor:\n",
    "    latents = latents.permute(0, 2, 1, 3, 4)  # [batch_size, num_channels, num_frames, height, width]\n",
    "    latents = 1 / vae.config.scaling_factor * latents\n",
    "\n",
    "    if grad:\n",
    "        frames = vae.decode(latents).sample\n",
    "    else:\n",
    "        with torch.no_grad(): frames = vae.decode(latents).sample\n",
    "    return frames.permute(0,2,1,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba6c95ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 47.52 GiB of which 32.25 MiB is free. Including non-PyTorch memory, this process has 47.40 GiB memory in use. Of the allocated memory 46.28 GiB is allocated by PyTorch, and 324.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m latents \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mlatent_dist\u001b[38;5;241m.\u001b[39msample() \u001b[38;5;241m*\u001b[39m vae\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mscaling_factor\n\u001b[1;32m      7\u001b[0m latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m vae\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mscaling_factor \u001b[38;5;241m*\u001b[39m latents\n\u001b[0;32m----> 8\u001b[0m recon \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/utils/accelerate_utils.py:46\u001b[0m, in \u001b[0;36mapply_forward_hook.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hf_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_hook, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpre_forward(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:1249\u001b[0m, in \u001b[0;36mAutoencoderKLCogVideoX.decode\u001b[0;34m(self, z, return_dict)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(decoded_slices)\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1249\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (decoded,)\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:1220\u001b[0m, in \u001b[0;36mAutoencoderKLCogVideoX._decode\u001b[0;34m(self, z, return_dict)\u001b[0m\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_quant_conv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1219\u001b[0m         z_intermediate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_quant_conv(z_intermediate)\n\u001b[0;32m-> 1220\u001b[0m     z_intermediate, conv_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_intermediate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1221\u001b[0m     dec\u001b[38;5;241m.\u001b[39mappend(z_intermediate)\n\u001b[1;32m   1223\u001b[0m dec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(dec, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:944\u001b[0m, in \u001b[0;36mCogVideoXDecoder3D.forward\u001b[0;34m(self, sample, temb, conv_cache)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, up_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_blocks):\n\u001b[1;32m    943\u001b[0m         conv_cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup_block_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 944\u001b[0m         hidden_states, new_conv_cache[conv_cache_key] \u001b[38;5;241m=\u001b[39m \u001b[43mup_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_cache_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# 3. Post-process\u001b[39;00m\n\u001b[1;32m    949\u001b[0m hidden_states, new_conv_cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm_out\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_out(\n\u001b[1;32m    950\u001b[0m     hidden_states, sample, conv_cache\u001b[38;5;241m=\u001b[39mconv_cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm_out\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    951\u001b[0m )\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:635\u001b[0m, in \u001b[0;36mCogVideoXUpBlock3D.forward\u001b[0;34m(self, hidden_states, temb, zq, conv_cache)\u001b[0m\n\u001b[1;32m    627\u001b[0m         hidden_states, new_conv_cache[conv_cache_key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    628\u001b[0m             resnet,\n\u001b[1;32m    629\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    632\u001b[0m             conv_cache\u001b[38;5;241m.\u001b[39mget(conv_cache_key),\n\u001b[1;32m    633\u001b[0m         )\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 635\u001b[0m         hidden_states, new_conv_cache[conv_cache_key] \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_cache_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m upsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers:\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:311\u001b[0m, in \u001b[0;36mCogVideoXResnetBlock3D.forward\u001b[0;34m(self, inputs, temb, zq, conv_cache)\u001b[0m\n\u001b[1;32m    308\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemb_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(temb))[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     hidden_states, new_conv_cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnorm2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(hidden_states)\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:193\u001b[0m, in \u001b[0;36mCogVideoXSpatialNorm3D.forward\u001b[0;34m(self, f, zq, conv_cache)\u001b[0m\n\u001b[1;32m    190\u001b[0m     zq \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(zq, size\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:])\n\u001b[1;32m    192\u001b[0m conv_y, new_conv_cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv_y\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_y(zq, conv_cache\u001b[38;5;241m=\u001b[39mconv_cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv_y\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 193\u001b[0m conv_b, new_conv_cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv_b\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconv_b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m norm_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_layer(f)\n\u001b[1;32m    196\u001b[0m new_f \u001b[38;5;241m=\u001b[39m norm_f \u001b[38;5;241m*\u001b[39m conv_y \u001b[38;5;241m+\u001b[39m conv_b\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:145\u001b[0m, in \u001b[0;36mCogVideoXCausalConv3d.forward\u001b[0;34m(self, inputs, conv_cache)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     conv_cache \u001b[38;5;241m=\u001b[39m inputs[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_kernel_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m--> 145\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, conv_cache\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:66\u001b[0m, in \u001b[0;36mCogVideoXSafeConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/conv.py:725\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/conv.py:720\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    710\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    719\u001b[0m     )\n\u001b[0;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 47.52 GiB of which 32.25 MiB is free. Including non-PyTorch memory, this process has 47.40 GiB memory in use. Of the allocated memory 46.28 GiB is allocated by PyTorch, and 324.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "uvs = head.batch_uv(batch[:1], resolution=256, rotation=False, sample_frames=29).permute(0,1,4,2,3) \n",
    "\n",
    "uvs = uvs.to(accelerator.device, dtype=vae.dtype)\n",
    "uvs = uvs.permute(0, 2, 1, 3, 4)  # [B, C, F, H, W]\n",
    "z = vae.encode(uvs)\n",
    "latents = z.latent_dist.sample() * vae.config.scaling_factor\n",
    "latents = 1 / vae.config.scaling_factor * latents\n",
    "recon = vae.decode(latents).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4343bccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(146.7351, device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_kl_loss(z):\n",
    "    mu = z.latent_dist.mean\n",
    "    logvar = z.latent_dist.logvar\n",
    "    # kl per latent unit\n",
    "    kl = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return kl\n",
    "\n",
    "kl = compute_kl_loss(z).sum()\n",
    "l1 = F.l1_loss(uvs, recon, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509094a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = encode_video(vae, uvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6875a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = decode_latents(vae, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eced6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "batch_size = 2\n",
    "train_steps = epoch * (len(dataset) // batch_size)\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    range(0, train_steps),\n",
    "    initial=1,\n",
    "    desc=\"Steps\",\n",
    ")\n",
    "\n",
    "for ep in epoch:\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        uvs = head.batch_uv(batch, resolution=256, rotation=False, sample_frames=150).permute(0,1,4,2,3) \n",
    "\n",
    "        uvs = uvs.to(accelerator.device, dtype=vae.dtype)\n",
    "        uvs = uvs.permute(0, 2, 1, 3, 4)  # [B, C, F, H, W]\n",
    "        latent_dist = vae.encode(uvs).latent_dist.sample() * vae.config.scaling_factor\n",
    "        \n",
    "        y = decode_latents(vae, z)\n",
    "\n",
    "        recon_loss = F.mse_loss(recon_x, x)\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.numel()\n",
    "        loss = recon_loss + beta * kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef910ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacity of 47.52 GiB of which 190.25 MiB is free. Including non-PyTorch memory, this process has 47.24 GiB memory in use. Of the allocated memory 45.79 GiB is allocated by PyTorch, and 673.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m uvs \u001b[38;5;241m=\u001b[39m uvs\u001b[38;5;241m.\u001b[39mto(accelerator\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mvae\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m      2\u001b[0m uvs \u001b[38;5;241m=\u001b[39m uvs\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m)  \u001b[38;5;66;03m# [B, C, F, H, W]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m latent_dist \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43muvs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/utils/accelerate_utils.py:46\u001b[0m, in \u001b[0;36mapply_forward_hook.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hf_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_hook, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpre_forward(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:1194\u001b[0m, in \u001b[0;36mAutoencoderKLCogVideoX.encode\u001b[0;34m(self, x, return_dict)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(encoded_slices)\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1194\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1196\u001b[0m posterior \u001b[38;5;241m=\u001b[39m DiagonalGaussianDistribution(h)\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:1166\u001b[0m, in \u001b[0;36mAutoencoderKLCogVideoX._encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1164\u001b[0m end_frame \u001b[38;5;241m=\u001b[39m frame_batch_size \u001b[38;5;241m*\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m remaining_frames\n\u001b[1;32m   1165\u001b[0m x_intermediate \u001b[38;5;241m=\u001b[39m x[:, :, start_frame:end_frame]\n\u001b[0;32m-> 1166\u001b[0m x_intermediate, conv_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_intermediate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_conv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m     x_intermediate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_conv(x_intermediate)\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:780\u001b[0m, in \u001b[0;36mCogVideoXEncoder3D.forward\u001b[0;34m(self, sample, temb, conv_cache)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, down_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_blocks):\n\u001b[1;32m    779\u001b[0m     conv_cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdown_block_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 780\u001b[0m     hidden_states, new_conv_cache[conv_cache_key] \u001b[38;5;241m=\u001b[39m \u001b[43mdown_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_cache_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;66;03m# 2. Mid\u001b[39;00m\n\u001b[1;32m    785\u001b[0m hidden_states, new_conv_cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmid_block\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmid_block(\n\u001b[1;32m    786\u001b[0m     hidden_states, temb, \u001b[38;5;28;01mNone\u001b[39;00m, conv_cache\u001b[38;5;241m=\u001b[39mconv_cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmid_block\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    787\u001b[0m )\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:433\u001b[0m, in \u001b[0;36mCogVideoXDownBlock3D.forward\u001b[0;34m(self, hidden_states, temb, zq, conv_cache)\u001b[0m\n\u001b[1;32m    425\u001b[0m         hidden_states, new_conv_cache[conv_cache_key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    426\u001b[0m             resnet,\n\u001b[1;32m    427\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    430\u001b[0m             conv_cache\u001b[38;5;241m.\u001b[39mget(conv_cache_key),\n\u001b[1;32m    431\u001b[0m         )\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m         hidden_states, new_conv_cache[conv_cache_key] \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_cache_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m downsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsamplers:\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:305\u001b[0m, in \u001b[0;36mCogVideoXResnetBlock3D.forward\u001b[0;34m(self, inputs, temb, zq, conv_cache)\u001b[0m\n\u001b[1;32m    302\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(hidden_states)\n\u001b[1;32m    304\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(hidden_states)\n\u001b[0;32m--> 305\u001b[0m hidden_states, new_conv_cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconv1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m temb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemb_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(temb))[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:138\u001b[0m, in \u001b[0;36mCogVideoXCausalConv3d.forward\u001b[0;34m(self, inputs, conv_cache)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: torch\u001b[38;5;241m.\u001b[39mTensor, conv_cache: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 138\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_context_parallel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplicate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    141\u001b[0m         conv_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/ondemand28/harryscz/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:134\u001b[0m, in \u001b[0;36mCogVideoXCausalConv3d.fake_context_parallel_forward\u001b[0;34m(self, inputs, conv_cache)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kernel_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    133\u001b[0m         cached_inputs \u001b[38;5;241m=\u001b[39m [conv_cache] \u001b[38;5;28;01mif\u001b[39;00m conv_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [inputs[:, :, :\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m*\u001b[39m (kernel_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 134\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_inputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacity of 47.52 GiB of which 190.25 MiB is free. Including non-PyTorch memory, this process has 47.24 GiB memory in use. Of the allocated memory 45.79 GiB is allocated by PyTorch, and 673.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c9c0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f34c837",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uvs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muvs\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'uvs' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db0450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
